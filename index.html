<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>LipAttention: Lipreading Guided Attention Diffusion Model</title>
  <style>
    :root {
      --bg: #fafafa;
      --text: #111827;
      --primary: #1f2937;
      --accent: #2563eb;
      --card: #ffffff;
      --shadow: rgba(0,0,0,0.06);
    }
    *{box-sizing:border-box;}
    body{
      margin:0;
      font-family:Inter,-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,Oxygen,Ubuntu,Cantarell,'Open Sans','Helvetica Neue',sans-serif;
      background:var(--bg);
      color:var(--text);
      line-height:1.6;
      word-break:keep-all;
    }
    a{color:var(--accent);text-decoration:none;}
    a:hover{text-decoration:underline;}

    /* ----- Header & Title ----- */
    header{
      text-align:center;
      padding:2rem 1rem 0;
    }
    .home-link{
      display:inline-block;
      margin-bottom:0.5rem;
      font-size:1.25rem;
    }
    .home-link span{
      display:inline-block;
      transform:translateY(2px);
    }
    h1{
      margin:0.5rem 0 0;
      font-size:clamp(1.8rem,3vw,2.5rem);
      font-weight:800;
    }
    .authors{
      margin:0.5rem 0 0.75rem;
      font-size:1.5rem;
    }
    .affiliation{font-style:italic;opacity:0.8;}
    .pill-links{
      display:flex;
      justify-content:center;
      gap:0.75rem;
      margin:0.75rem 0 1.5rem;
      flex-wrap:wrap;
    }
    .pill{
      display:inline-flex;
      align-items:center;
      gap:0.4rem;
      background:var(--primary);
      color:#fff;
      padding:0.45rem 0.9rem;
      border-radius:9999px;
      font-weight:600;
      font-size:0.875rem;
    }
    .pill svg{width:14px;height:14px;}

    /* ----- Figures Row ----- */
    .figures{
      max-width:1100px;
      margin:0 auto 2.5rem;
      display:flex;
      flex-wrap:wrap;
      justify-content:center;
      gap:1.25rem;
    }
    .figures img{
      max-width:350px;
      width:100%;
      border-radius:0.75rem;
      box-shadow:0 4px 12px var(--shadow);
    }

    /* ----- Abstract ----- */
    .abstract{
      max-width:750px;
      margin:0 auto 3.5rem;
      padding:0 1rem;
    }
    .abstract h2{
      text-align:center;
      font-size:1.5rem;
      font-weight:700;
      margin:0 0 1rem;
    }
    .abstract p{margin:0; text-align:justify;}

    /* ----- Comparison Table ----- */
    .comparison{
      max-width:1300px;
      margin:0 auto 4rem;
      padding:0 0.5rem;
    }
    .comparison h2{
      text-align:center;
      font-size:1.5rem;
      font-weight:700;
      margin:0 0 1.25rem;
    }
    .video-table{
      width:100%;
      border-collapse:separate;
      border-spacing:0.75rem 0.85rem;
    }
    .video-table thead th{
      font-weight:600;
      font-size:0.9rem;
      text-align:center;
      padding:0.25rem 0.4rem;
    }
    .video-table tbody td{
      text-align:center;
      vertical-align:top;
    }
    .video-table video{
      width:110px;
      height:110px;
      border-radius:0.5rem;
      background:#000;
    }
    .transcript{
      width:210px;
      text-align:left;
      font-size:0.875rem;
    }

    /* ------ Footer ------ */
    footer{
      text-align:center;
      font-size:0.8rem;
      color:#6b7280;
      padding:2rem 1rem 2.5rem;
    }
  </style>
</head>
<body>

<header>
  <a class="home-link" href="/" title="Home"><span>üè†</span></a>
  <h1>LipAttention: Lipreading-Guided Attention Fusion <br> for Diffusion Speech Generation from Silent Video</h1>
  <p class="authors">Gunwoo&nbsp;Lee, Yoori&nbsp;Oh, Yoseob&nbsp;Han, </p>
  <p class="affiliation">Soongsil University, Seoul National University</p>
  <div class="pill-links">
    <a class="pill" href="#"><svg viewBox="0 0 24 24" fill="currentColor" stroke="currentColor"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2z"></path></svg> arXiv</a>
    <a class="pill" href="#">üíª Code</a>
  </div>
</header>

<!-- Figures Row -->
<section class="figures">
  <img src="Figure/Sample_architecture.png" alt="Overall Architecture">
</section>

<!-- Abstract -->
<section class="abstract">
  <h2>Abstract</h2>
  <p>
    Video-to-speech aims to predict accurate spoken sentences and generate natural sounding speech from silent videos. Although various  approaches have been proposed, achieving both sentence level accuracy and high speech quality remains challenging. In this paper, we proposed a method to construct a unified conditional representation to maximize the performance of a diffusion based speech generation model. During training, ground-truth text is directly utilized, and an attention mechanism is applied to reinforce the correlation between lip movements and text, thereby improving sentence accuracy. During inference, pseudo text is generated via lipreading and used as guidance for the sampling process. Our model demonstrates superior performance on the LRS2 and LRS3 datasets, outperforming previous approaches particularly in Word Error Rate(WER) while maintaining high speech quality. Human evaluation via Mean Opinion Score(MOS) further comfirms the model's effectiveness.
  </p>
</section>

<!-- Comparison Table -->
<section class="comparison">
  <h2>Comparison results on LRS3 dataset</h2>
  <table class="video-table">
    <thead>
      <tr>
        <th>Silent video</th><th>Ground Truth</th><th>SVTS</th><th>Intelligible</th><th>V2SFlow‚ÄëA</th><th>DiffV2S</th><th>LTBS</th><th>V2SFlow‚ÄëV</th><th>Text</th>
      </tr>
    </thead>
    <tbody>
      <!-- Row 1 -->
      <tr>
        <td><video src="s1_silent.mp4" controls></video></td>
        <td><video src="s1_gt.mp4" controls></video></td>
        <td><video src="s1_svts.mp4" controls></video></td>
        <td><video src="s1_intel.mp4" controls></video></td>
        <td><video src="s1_v2s_a.mp4" controls></video></td>
        <td><video src="s1_diff.mp4" controls></video></td>
        <td><video src="s1_ltbs.mp4" controls></video></td>
        <td><video src="s1_v2s_v.mp4" controls></video></td>
        <td class="transcript">but you know what</td>
      </tr>

      <!-- Row 2 (duplicate rows can be copied & modified) -->
      <tr>
        <td><video src="s2_silent.mp4" controls></video></td>
        <td><video src="s2_gt.mp4" controls></video></td>
        <td><video src="s2_svts.mp4" controls></video></td>
        <td><video src="s2_intel.mp4" controls></video></td>
        <td><video src="s2_v2s_a.mp4" controls></video></td>
        <td><video src="s2_diff.mp4" controls></video></td>
        <td><video src="s2_ltbs.mp4" controls></video></td>
        <td><video src="s2_v2s_v.mp4" controls></video></td>
        <td class="transcript">so the answer to the second question can we change</td>
      </tr>

      <!-- Additional rows ... -->
    </tbody>
  </table>
</section>

<footer>
  Template adapted from original LipVoicer &amp; V2SFlow demos ‚Ä¢ Replace <code>.mp4</code> placeholders with your own videos.
</footer>

</body>
</html>
